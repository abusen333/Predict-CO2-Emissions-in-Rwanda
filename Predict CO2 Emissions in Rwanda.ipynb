{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "from haversine import haversine\n",
    "\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "bold = ['\\033[1m', '\\033[0m']\n",
    "seed = 228"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv') # index_col=0 is the id column\n",
    "test = pd.read_csv('test.csv') # index_col=0 is the id column\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "y = train['emission']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ID Generation:\n",
    "The code first generates a unique ID for each row by combining latitude and longitude. It extracts digits from both coordinates, concatenates them, and then maps them to a new unique ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(row):\n",
    "    return int(''.join(filter(str.isdigit, str(row['latitude']))) + ''.join(filter(str.isdigit, str(row['longitude']))))\n",
    "\n",
    "train['id'] = train[['latitude', 'longitude']].apply(lambda row: get_id(row), axis=1)\n",
    "test['id'] = test[['latitude', 'longitude']].apply(lambda row: get_id(row), axis=1)\n",
    "new_ids = {id_: new_id for new_id, id_ in enumerate(train['id'].unique())}\n",
    "train['id'] = train['id'].map(new_ids)\n",
    "test['id'] = test['id'].map(new_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract Month from Year and Week:\n",
    "A function to extract the month given a year and week number is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_month(row):\n",
    "    date = dt.datetime.strptime(f'{row[\"year\"]}-{row[\"week_no\"]+1}-1', \"%Y-%W-%w\")\n",
    "    return date.month\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Geographic Points of Interest:\n",
    "Several important geographic locations are defined for later distance computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rwanda_center = (-1.9607, 29.9707)\n",
    "park_biega = (-1.8866, 28.4518)\n",
    "kirumba = (-0.5658, 29.1714)\n",
    "massif = (-3.42, 28.592)\n",
    "lake = (-2.0073, 31.6269)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compute Distances to Cluster Centers:\n",
    "The code computes distances from given points to several cluster centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_features(df, cluster_centers):\n",
    "    for i, cc in enumerate(cluster_centers.values()):\n",
    "        df[f'cluster_{i}'] = df.apply(lambda x: haversine((x['latitude'], x['longitude']), cc, unit='ft'), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Preprocessing:\n",
    "This section is the bulk of the code. It involves:\n",
    "\n",
    " 1. Filtering columns\n",
    " 2. Forward and backward filling missing values\n",
    " 2. Creating several lag and rotational features\n",
    " 4. Calculating distances to defined geographic locations\n",
    " 5. Extracting month and identifying periods of COVID-19 and lockdowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    # Select important columns\n",
    "   \n",
    "    cols_save = ['id', 'latitude', 'longitude', 'year', 'week_no', 'Ozone_solar_azimuth_angle']\n",
    "    df = df[cols_save]\n",
    "    \n",
    "    # Fill missing values for 'Ozone_solar_azimuth_angle'\n",
    "    good_col = 'Ozone_solar_azimuth_angle'\n",
    "    df[good_col] = df.groupby(['id', 'year'])[good_col].ffill().bfill()\n",
    "    df[f'{good_col}_lag_1'] = df.groupby(['id', 'year'])[good_col].shift(1).fillna(0)\n",
    "    \n",
    "    # Compute rotated features for latitude and longitude\n",
    "    df['rot_15_x'] = (np.cos(np.radians(15)) * df['longitude']) + \\\n",
    "                     (np.sin(np.radians(15)) * df['latitude'])\n",
    "    \n",
    "    df['rot_15_y'] = (np.cos(np.radians(15)) * df['latitude']) + \\\n",
    "                     (np.sin(np.radians(15)) * df['longitude'])\n",
    "\n",
    "    df['rot_30_x'] = (np.cos(np.radians(30)) * df['longitude']) + \\\n",
    "                     (np.sin(np.radians(30)) * df['latitude'])\n",
    "\n",
    "    df['rot_30_y'] = (np.cos(np.radians(30)) * df['latitude']) + \\\n",
    "                     (np.sin(np.radians(30)) * df['longitude'])\n",
    "    \n",
    "    # Calculate distances to specified geographic locations\n",
    "    for col, coors in zip(\n",
    "        ['dist_rwanda', 'dist_park', 'dist_kirumba', 'dist_massif', 'dist_lake'], \n",
    "        [rwanda_center, park_biega, kirumba, massif, lake]\n",
    "    ):\n",
    "        df[col] = df.apply(lambda x: haversine((x['latitude'], x['longitude']), coors, unit='ft'), axis=1)\n",
    "    \n",
    "    # Extract month and label periods of COVID-19 and lockdowns\n",
    "    df['month'] = df[['year', 'week_no']].apply(lambda row: get_month(row), axis=1)\n",
    "    df['is_covid'] = (df['year'] == 2020) & (df['month'] > 2) | (df['year'] == 2021) & (df['month'] == 1)\n",
    "    df['is_lockdown'] = (df['year'] == 2020) & ((df['month'].isin([3,4])))\n",
    "    \n",
    "    df.fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "train = preprocessing(train)\n",
    "test = preprocessing(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Clustering:\n",
    "Based on latitude and longitude, KMeans clustering is applied to group locations into 12 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "coordinates = df[['latitude', 'longitude']].values\n",
    "clustering = KMeans(n_clusters=25, max_iter=100, random_state=seed).fit(coordinates)\n",
    "cluster_centers = {i: tuple(centroid) for i, centroid in enumerate(clustering.cluster_centers_)}\n",
    "df = cluster_features(df, cluster_centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Splitting and Cleaning:\n",
    "Finally, the preprocessed dataframe is split back into train and test, and unused variables are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = df.iloc[:-len(test),:]\n",
    "test = df.iloc[-len(test):,:]\n",
    "del df\n",
    "\n",
    "X = train.drop('id', axis=1)\n",
    "test = test.drop('id', axis=1)\n",
    "test=test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 14:44:14,002] A new study created in memory with name: no-name-44f8eae4-9a0b-4a0d-b78a-d25b507a5b4f\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d14d255f5a64a0e928bc542a14fbb23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "from optuna.integration import XGBoostPruningCallback\n",
    "\n",
    "dtrain = xgb.DMatrix(X, label=y)\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse',\n",
    "        'booster': trial.suggest_categorical('booster', ['gbtree', 'gblinear', 'dart']),\n",
    "        'lambda': trial.suggest_float('lambda', 1e-5, 1, log=True),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-5, 1, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.1, 1),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 9),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 9),\n",
    "        'eta': trial.suggest_float('eta', 1e-5, 1, log=True),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 0.4)\n",
    "\n",
    "    }\n",
    "    \n",
    "    pruning_callback = XGBoostPruningCallback(trial, 'test-rmse')\n",
    "    cv_result = xgb.cv(param, dtrain, num_boost_round=5000, nfold=3, callbacks=[pruning_callback], verbose_eval=False)\n",
    "    \n",
    "    return cv_result[\"test-rmse-mean\"].values[-1]\n",
    "\n",
    "study = optuna.create_study(direction='minimize', pruner=optuna.pruners.MedianPruner())\n",
    "study.optimize(objective, n_trials=30, show_progress_bar=True)\n",
    "\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: \", trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1 RMSE: \u001b[1m17.283086\u001b[0m\n",
      "FOLD 2 RMSE: \u001b[1m23.55203\u001b[0m\n",
      "FOLD 3 RMSE: \u001b[1m19.292354\u001b[0m\n",
      "\n",
      "CV RMSE: \u001b[1m20.04249\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "\n",
    "xgb_params = {\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.01,\n",
    "    'colsample_bytree': 0.66,\n",
    "    'subsample': 0.76,\n",
    "    'min_child_weight': 2,\n",
    "    'lambda': 1, \n",
    "    'gamma': 1,\n",
    "    \n",
    "    # 'tree_method': 'gpu_hist',\n",
    "    'booster': 'gbtree',\n",
    "    # 'predictor':'gpu_predictor',\n",
    "    'seed': seed,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse'\n",
    "}\n",
    "\n",
    "scores = []\n",
    "for fold, (train_idx, val_idx) in enumerate(logo.split(X, y, X['year'])):\n",
    "\n",
    "    dtrain = xgb.DMatrix(\n",
    "        X.iloc[train_idx], \n",
    "        label=y.iloc[train_idx]\n",
    "    )\n",
    "    dvalid = xgb.DMatrix(\n",
    "        X.iloc[val_idx], \n",
    "        label=y.iloc[val_idx]\n",
    "    )\n",
    "\n",
    "    model = xgb.train(\n",
    "        params=xgb_params, \n",
    "        dtrain=dtrain, \n",
    "        num_boost_round=5000,\n",
    "        evals=[(dvalid, 'eval')], \n",
    "        verbose_eval=False,\n",
    "        callbacks=[\n",
    "            xgb.callback.EarlyStopping(\n",
    "                rounds=500,\n",
    "                data_name='eval',\n",
    "                maximize=False,\n",
    "                save_best=True\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    val_preds = model.predict(dvalid)\n",
    "    val_score = rmse(y.iloc[val_idx], val_preds)\n",
    "    scores.append(val_score)\n",
    "    print(f'FOLD {fold+1} RMSE: {bold[0]}{round(val_score, 6)}{bold[1]}')\n",
    "    \n",
    "    del dtrain, dvalid, val_preds, val_score, model\n",
    "    gc.collect()\n",
    "\n",
    "print(f'\\nCV RMSE: {bold[0]}{round(np.mean(scores), 6)}{bold[1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
